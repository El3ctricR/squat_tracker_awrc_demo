<p align="center">
  <img src="logo.png" alt="SquatAI logo" width="220">
</p>

# ğŸ‹ï¸ Real-Time Squat Analysis Tool (YOLOv8 + PyQt5)

This project provides a real-time squat form analyser that uses **YOLOv8 pose estimation** inside a **PyQt5 GUI**.  
It measures **knee angle** and **torso angle**, gives a traffic-light depth cue, counts reps, and plays an audio beep for every valid squat.

---

## ğŸ“¸ Features

- **Real-time pose** (17 COCO key-points) via YOLOv8.
- **Metrics**
  - Knee angle (hip â€“ knee â€“ ankle)
  - Torso angle (shoulder â€“ hip vs vertical)
- **Traffic light feedback**
  - ğŸŸ¢ â‰¤ 90 Â°   (legal depth)
  - ğŸŸ  91 â€“ 110 Â° (approaching)
  - ğŸ”´ > 110 Â°   (not deep enough)
- **Rep counter** with audio beep.
- **Clean GUI** (Start / Stop, live feed, overlays, running totals).

---

## ğŸ’¡ Best Results

> **Place the camera side-on to the athlete.**  
> A lateral view captures knee flexion and torso angle most accurately in 2-D.

---

## ğŸš€ Getting Started

### 1  Clone the repository
```bash
git clone https://github.com/El3ctricR/squat_tracker_awrc_demo.git
cd squat_tracker_awrc_demo
```

---

### 2  Install dependencies
> Requires **Python 3.8 +**. A CUDA-capable GPU is recommended for 30 FPS+.

```bash
pip install -r requirements.txt
```

<details>
<summary>If you prefer manual installation, expand for commands</summary>

```bash
pip install ultralytics==8.0.20
pip install opencv-python
pip install numpy
pip install PyQt5
```
</details>

*Ensure your PyTorch/CUDA versions match your GPU setup â€” see the
[Pytorch install guide](https://pytorch.org/get-started/locally).*

---

## ğŸ§° Usage
```bash
python squat_gui_app.py
```
* In the GUI click **Start** to begin analysis.  
* Click **Stop** to end the session.

During a session you will see:
- Live webcam feed.
- Knee / Torso angles (Â°).
- Traffic-light depth icon.
- Running rep counter with a beep for each valid squat.

---

## ğŸ“ File Structure
```
â”œâ”€â”€ squat_gui_app.py        # Main application (GUI + analysis)
â”œâ”€â”€ yolov8n-pose.pt         # YOLOv8 pose model (download separately if absent)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # This documentation
```

---

## ğŸ“„ License

Released under the **MIT License**.  
See the included `LICENSE` file for full terms.

---

## ğŸ™ Acknowledgements

- ğŸ¤– [Ultralytics / YOLOv8](https://github.com/ultralytics/ultralytics) â€“ pose estimation backbone  
- ğŸ–¼ï¸ [OpenCV](https://opencv.org/) â€“ real-time computer vision  
- ğŸ’» [PyQt5](https://pypi.org/project/PyQt5/) â€“ GUI framework  
- ğŸ”‰ Windows `winsound` module â€“ audio feedback for reps  

---

## ğŸ“ Notes & Troubleshooting

| Topic | Tip |
|-------|-----|
| **Audio on macOS/Linux** | Replace `winsound.Beep()` with `playsound` or `pygame.mixer.Sound`. |
| **Model download** | If `yolov8n-pose.pt` is missing, download it from the Ultralytics repo or run:<br>`from ultralytics import YOLO; YOLO('yolov8n-pose.pt')`. |
| **Performance** | `yolov8n-pose.pt` offers ~30 FPS on an RTX 3060. Larger models improve accuracy at the cost of speed. |
| **Camera view** | Keep the athlete fully in frame and perpendicular to the camera plane for the most reliable depth detection. |

---

Happy squatting! Feel free to open issues or PRs if you improve the tool.

